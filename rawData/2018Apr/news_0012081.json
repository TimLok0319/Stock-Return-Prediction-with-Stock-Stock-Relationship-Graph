{"organizations": [], "uuid": "d35820ec80f717b6809ecfc29bcb044389a8560b", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 0, "shares": 0, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "uk.reuters.com", "main_image": "https://s4.reutersmedia.net/resources_v2/images/rcom-default.png", "site_section": "http://feeds.reuters.com/reuters/UKScienceNews/", "section_title": "Reuters: Science News", "url": "https://uk.reuters.com/article/us-tech-korea-boycott/researchers-to-boycott-south-korean-university-over-ai-weapons-work-idUKKCN1HB392", "country": "US", "domain_rank": 408, "title": "Researchers to boycott South Korean university over AI weapons work", "performance_score": 0, "site": "reuters.com", "participants_count": 0, "title_full": "", "spam_score": 0.0, "site_type": "news", "published": "2018-04-05T02:41:00.000+03:00", "replies_count": 0, "uuid": "d35820ec80f717b6809ecfc29bcb044389a8560b"}, "author": "", "url": "https://uk.reuters.com/article/us-tech-korea-boycott/researchers-to-boycott-south-korean-university-over-ai-weapons-work-idUKKCN1HB392", "ord_in_thread": 0, "title": "Researchers to boycott South Korean university over AI weapons work", "locations": [], "entities": {"persons": [{"name": "andrea shalal", "sentiment": "none"}, {"name": "sung-chul shin", "sentiment": "none"}], "locations": [{"name": "south korea", "sentiment": "none"}, {"name": "kaist", "sentiment": "none"}], "organizations": [{"name": "hanwha systems", "sentiment": "none"}, {"name": "min read  berlin", "sentiment": "none"}, {"name": "reuters", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "April 4, 2018 / 11:44 PM / Updated 22 minutes ago Researchers to boycott South Korean university over AI weapons work Andrea Shalal 4 Min Read \nBERLIN (Reuters) - Over 50 top Artificial Intelligence researchers on Wednesday announced a boycott of KAIST, South Korea’s top university, after it opened what they called an AI weapons lab with one of South Korea’s largest companies. \nThe researchers, based in 30 countries, said they would refrain from visiting KAIST, hosting visitors from the university, or cooperating with its research programs until it pledged to refrain from developing AI weapons without “meaningful human control”. \nKAIST, which opened the center in February with Hanwha Systems, one of two South Korean makers of cluster munitions, responded within hours, saying it had “no intention to engage in development of lethal autonomous weapons systems and killer robots.” \nUniversity President Sung-Chul Shin said the university was “significantly aware” of ethical concerns regarding Artificial Intelligence, adding, “I reaffirm once again that KAIST will not conduct any research activities counter to human dignity including autonomous weapons lacking meaningful human control.” \nThe university said the new Research Centre for the Convergence of National Defence and Artificial Intelligence would focus on using AI for command and control systems, navigation for large unmanned undersea vehicles, smart aircraft training and tracking and recognition of objects. \nToby Walsh, the professor at the University of New South Wales in Sydney who organized the boycott, said the university’s quick response was a success, but he needed to speak with all those who signed the letter before calling off the boycott. \n“KAIST has made two significant concessions: not to develop autonomous weapons and to ensure meaningful human control,” he said, adding that the university’s response would add weight to U.N. discussions taking place next week on the overall issue. \nWalsh said it remained unclear how one could establish meaningful human control of an unmanned submarine - one of the launch projects - when it was under the sea and unable to communicate. \nIn an open letter announcing the boycott, the researchers had warned: “If developed, autonomous weapons will ... permit war to be fought faster and at a scale great than ever before. They will have the potential to be weapons of terror.” \nThey cited effective bans on previous arms technologies and urged KAIST ban any work on lethal autonomous weapons, and to refrain from AI uses that would harm human lives. \nAI is the field in computer science that aims to create machines able to perceive the environment and make decisions. \nThe letter, also signed by top experts on deep learning and robotics, was released ahead of next Monday’s meeting in Geneva by 123 U.N. member countries on the challenges posed by lethal autonomous weapons, which critics describe as “killer robots”. \nWalsh told Reuters there were many potential good uses of robotics and Artificial Intelligence in the military, including removing humans from dangerous task such as clearing minefields. \n“But we should not hand over the decision of who lives or dies to a machine. This crosses a clear moral line,” he said. “We should not let robots decide who lives and who dies.” Reporting by Andrea Shalal; Editing by Alison Williams and Diane Craft", "external_links": [], "published": "2018-04-05T02:41:00.000+03:00", "crawled": "2018-04-05T03:17:17.003+03:00", "highlightTitle": ""}